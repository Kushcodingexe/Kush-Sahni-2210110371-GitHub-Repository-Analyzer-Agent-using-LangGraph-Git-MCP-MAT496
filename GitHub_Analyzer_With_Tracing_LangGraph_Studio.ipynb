{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Repository Analyzer Agent - With LangSmith Tracing\n",
    "\n",
    "**Author**: Kush Sahni (2210110371)  \n",
    "**Course**: MAT496 - Introduction to LLM  \n",
    "**Project**: GitHub Repository Analyzer using LangGraph\n",
    "\n",
    "---\n",
    "\n",
    "##  What This Notebook Demonstrates\n",
    "\n",
    "This notebook shows the core concepts of building an AI agent with **full observability**:\n",
    "\n",
    "1. **State Management** - How agents maintain memory\n",
    "2. **Tool Design** - GitHub API integration  \n",
    "3. **ReAct Pattern** - Reasoning + Acting loop\n",
    "4. **LangSmith Tracing** - Complete visibility into agent execution \n",
    "5. **LangGraph Studio Export** - Visual graph editing and testing \n",
    "\n",
    "Let's build with full observability! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup\n",
    "\n",
    "First, let's set up our environment with tracing enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run only once)\n",
    "# !pip install langchain langchain-openai langgraph python-dotenv PyGithub langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\" Environment loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable LangSmith Tracing\n",
    "\n",
    " **LangSmith** provides complete observability:\n",
    "- See every LLM call and response\n",
    "- Track all tool invocations\n",
    "- Monitor token usage and costs\n",
    "- Debug issues easily\n",
    "- Share traces with team\n",
    "\n",
    "Get your API key at: [https://smith.langchain.com/settings](https://smith.langchain.com/settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangSmith tracing enabled!\n",
      "   Project: GitHub-Analyzer-Simplified\n",
      "   View traces at: https://smith.langchain.com/\n",
      "\n",
      " All agent runs will be automatically traced!\n"
     ]
    }
   ],
   "source": [
    "# Enable LangSmith tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GitHub-Analyzer-Simplified\"\n",
    "\n",
    "# Check if LangSmith API key is configured\n",
    "langsmith_key = os.getenv(\"LANGCHAIN_API_KEY\") or os.getenv(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "if langsmith_key:\n",
    "    print(\" LangSmith tracing enabled!\")\n",
    "    print(f\"   Project: {os.environ['LANGCHAIN_PROJECT']}\")\n",
    "    print(\"   View traces at: https://smith.langchain.com/\")\n",
    "    print(\"\\n All agent runs will be automatically traced!\")\n",
    "else:\n",
    "    print(\"  LangSmith API key not found\")\n",
    "    print(\"   Tracing is disabled. Add LANGCHAIN_API_KEY to .env to enable\")\n",
    "    print(\"   Get your key at: https://smith.langchain.com/settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Status:\n",
      "==================================================\n",
      "GitHub Token:  \n",
      "OpenAI API:    \n",
      "LangSmith API: \n"
     ]
    }
   ],
   "source": [
    "# Verify API keys\n",
    "print(\"API Key Status:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"GitHub Token:  {'' if os.getenv('GITHUB_TOKEN') else ''}\")\n",
    "print(f\"OpenAI API:    {'' if os.getenv('OPENAI_API_KEY') else ''}\")\n",
    "print(f\"LangSmith API: {'' if langsmith_key else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Core Concepts\n",
    "\n",
    "### 2.1 State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " State schema defined with tracing!\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import add_messages\n",
    "from langsmith import traceable\n",
    "\n",
    "class GitHubAgentState(TypedDict):\n",
    "    \"\"\"State schema for our GitHub analyzer agent.\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    files: dict[str, str]\n",
    "    current_repo: str | None\n",
    "    remaining_steps: int\n",
    "\n",
    "@traceable(name=\"get_initial_state\")\n",
    "def get_initial_state() -> GitHubAgentState:\n",
    "    \"\"\"Create a fresh state.\"\"\"\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"files\": {},\n",
    "        \"current_repo\": None,\n",
    "        \"remaining_steps\": 20\n",
    "    }\n",
    "\n",
    "print(\" State schema defined with tracing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages after adding:\n",
      "1. HumanMessage: What is LangGraph?\n",
      "2. AIMessage: LangGraph is a framework for building stateful agents.\n",
      "\n",
      " Messages automatically accumulated!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Demonstrate add_messages behavior\n",
    "messages = []\n",
    "messages = add_messages(messages, [HumanMessage(content=\"What is LangGraph?\")])\n",
    "messages = add_messages(messages, [AIMessage(content=\"LangGraph is a framework for building stateful agents.\")])\n",
    "\n",
    "print(\"Messages after adding:\")\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"{i}. {msg.__class__.__name__}: {msg.content}\")\n",
    "\n",
    "print(\"\\n Messages automatically accumulated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Building Tools with Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GitHub client initialized\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from github import Github\n",
    "import base64\n",
    "\n",
    "# Initialize GitHub client\n",
    "github_client = Github(os.getenv(\"GITHUB_TOKEN\"))\n",
    "\n",
    "print(\" GitHub client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tool 1: get_repository_info (with tracing)\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "@traceable(name=\"get_repository_info\")  # LangSmith will trace this tool\n",
    "def get_repository_info(repo_name: str) -> str:\n",
    "    \"\"\"Get basic information about a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_name: Repository name in 'owner/repo' format\n",
    "    \n",
    "    Returns:\n",
    "        Formatted repository information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        repo = github_client.get_repo(repo_name)\n",
    "        \n",
    "        info = f\"\"\"# Repository: {repo.full_name}\n",
    "\n",
    "**Description:** {repo.description or 'No description'}\n",
    "**Stars:**  {repo.stargazers_count:,}\n",
    "**Forks:**  {repo.forks_count:,}\n",
    "**Language:** {repo.language or 'Not specified'}\n",
    "**Open Issues:**  {repo.open_issues_count}\n",
    "**Last Updated:** {repo.updated_at}\n",
    "**URL:** {repo.html_url}\n",
    "\"\"\"\n",
    "        return info\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\" Tool 1: get_repository_info (with tracing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tool 2: list_repository_structure (with tracing)\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "@traceable(name=\"list_repository_structure\")\n",
    "def list_repository_structure(repo_name: str, path: str = \"\", max_depth: int = 2) -> str:\n",
    "    \"\"\"Get directory tree structure of a GitHub repository.\"\"\"\n",
    "    try:\n",
    "        repo = github_client.get_repo(repo_name)\n",
    "        \n",
    "        def build_tree(current_path: str, depth: int = 0, prefix: str = \"\") -> list[str]:\n",
    "            if depth > max_depth:\n",
    "                return []\n",
    "            \n",
    "            output = []\n",
    "            contents = repo.get_contents(current_path)\n",
    "            \n",
    "            if isinstance(contents, list):\n",
    "                dirs = sorted([c for c in contents if c.type == \"dir\"], key=lambda x: x.name)\n",
    "                files = sorted([c for c in contents if c.type == \"file\"], key=lambda x: x.name)\n",
    "                contents = dirs + files\n",
    "            else:\n",
    "                contents = [contents]\n",
    "            \n",
    "            for idx, item in enumerate(contents[:20]):\n",
    "                is_last = idx == min(len(contents), 20) - 1\n",
    "                connector = \" \" if is_last else \" \"\n",
    "                \n",
    "                if item.type == \"dir\":\n",
    "                    output.append(f\"{prefix}{connector} {item.name}/\")\n",
    "                    if depth < max_depth:\n",
    "                        new_prefix = prefix + (\"    \" if is_last else \"   \")\n",
    "                        output.extend(build_tree(item.path, depth + 1, new_prefix))\n",
    "                else:\n",
    "                    output.append(f\"{prefix}{connector} {item.name}\")\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        tree = build_tree(path)\n",
    "        header = f\"Repository: {repo_name}\\nPath: /{path or 'root'}\\n\" + \"=\"*50 + \"\\n\"\n",
    "        return header + \"\\n\".join(tree)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\" Tool 2: list_repository_structure (with tracing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tool 3: read_file_from_repo (with tracing)\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "@traceable(name=\"read_file_from_repo\")\n",
    "def read_file_from_repo(repo_name: str, file_path: str, ref: str = \"main\") -> str:\n",
    "    \"\"\"Read a specific file from a GitHub repository.\"\"\"\n",
    "    try:\n",
    "        repo = github_client.get_repo(repo_name)\n",
    "        \n",
    "        try:\n",
    "            file_content = repo.get_contents(file_path, ref=ref)\n",
    "        except:\n",
    "            for alt_ref in [\"master\", \"main\", \"develop\"]:\n",
    "                try:\n",
    "                    file_content = repo.get_contents(file_path, ref=alt_ref)\n",
    "                    ref = alt_ref\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                return f\"File not found: {file_path}\"\n",
    "        \n",
    "        if isinstance(file_content, list):\n",
    "            return f\"Error: {file_path} is a directory\"\n",
    "        \n",
    "        content = base64.b64decode(file_content.content).decode('utf-8')\n",
    "        \n",
    "        return f\"\"\"# File: {file_path}\n",
    "Repository: {repo_name}\n",
    "Branch: {ref}\n",
    "\n",
    "{'='*60}\n",
    "\n",
    "{content}\n",
    "\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\" Tool 3: read_file_from_repo (with tracing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Building the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GitHub Analyzer Agent created with full tracing!\n",
      "   Model: gpt-4o-mini\n",
      "   Tools: 3\n",
      "   Graph: Manually constructed with agent_node and tool_node\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Gather all tools\n",
    "tools = [\n",
    "    get_repository_info,\n",
    "    list_repository_structure,\n",
    "    read_file_from_repo\n",
    "]\n",
    "\n",
    "# Bind tools to the model\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# System prompt\n",
    "SYSTEM_PROMPT = f\"\"\"You are a helpful GitHub Repository Analyzer Agent.\n",
    "\n",
    "**Current Date:** {datetime.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "**Your Capabilities:**\n",
    "- Getting repository information (stars, language, description)\n",
    "- Listing directory structures\n",
    "- Reading source code files\n",
    "\n",
    "**Guidelines:**\n",
    "- Be concise in your analysis\n",
    "- Focus on answering the user's specific question\n",
    "- Use tools to gather information before answering\n",
    "\"\"\"\n",
    "\n",
    "# Define the agent node\n",
    "@traceable(name=\"agent_node\")\n",
    "def agent_node(state: GitHubAgentState) -> dict:\n",
    "    \"\"\"The agent node that calls the LLM.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Prepend system message if not already present\n",
    "    if not messages or not isinstance(messages[0], SystemMessage):\n",
    "        messages = [SystemMessage(content=SYSTEM_PROMPT)] + list(messages)\n",
    "    \n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define the conditional edge function\n",
    "def should_continue(state: GitHubAgentState) -> str:\n",
    "    \"\"\"Determine if we should continue to tools or end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the LLM made tool calls, route to tools\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, end\n",
    "    return END\n",
    "\n",
    "# Create the tool node\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Build the graph manually\n",
    "workflow = StateGraph(GitHubAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Tools always go back to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "agent = workflow.compile()\n",
    "\n",
    "print(\"✅ GitHub Analyzer Agent created with full tracing!\")\n",
    "print(f\"   Model: {model.model_name}\")\n",
    "print(f\"   Tools: {len(tools)}\")\n",
    "print(\"   Graph: Manually constructed with agent_node and tool_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Agent for LangGraph Studio\n",
    "\n",
    "This cell automatically creates a `.py` file that can be loaded in LangGraph Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exported agent to: github_analyzer_studio.py\n",
      "\n",
      " To use in LangGraph Studio:\n",
      "   1. Open LangGraph Studio\n",
      "   2. Load 'github_analyzer_studio.py'\n",
      "   3. The 'graph' variable will be auto-detected\n",
      "   4. You can now visualize and test interactively!\n"
     ]
    }
   ],
   "source": [
    "# Export agent code for LangGraph Studio\n",
    "export_code = '''\"\"\"GitHub Analyzer Agent for LangGraph Studio\n",
    "\n",
    "Auto-generated from notebook. Load this file in LangGraph Studio.\n",
    "\"\"\"\n",
    "import os\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import add_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from github import Github\n",
    "from langsmith import traceable\n",
    "import base64\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GitHub-Analyzer-Studio\"\n",
    "\n",
    "github_client = Github(os.getenv(\"GITHUB_TOKEN\"))\n",
    "\n",
    "class GitHubAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    files: dict[str, str]\n",
    "    current_repo: str | None\n",
    "    remaining_steps: int\n",
    "\n",
    "@tool\n",
    "@traceable\n",
    "def get_repository_info(repo_name: str) -> str:\n",
    "    \"\"\"Get basic information about a GitHub repository.\"\"\"\n",
    "    try:\n",
    "        repo = github_client.get_repo(repo_name)\n",
    "        return f\"\"\"# {repo.full_name}\n",
    " {repo.stargazers_count:,} stars |  {repo.forks_count:,} forks\n",
    "{repo.description or 'No description'}\n",
    "Language: {repo.language}\n",
    "{repo.html_url}\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "@tool\n",
    "@traceable\n",
    "def list_repository_structure(repo_name: str, path: str = \"\", max_depth: int = 2) -> str:\n",
    "    \"\"\"Get directory tree of a repository.\"\"\"\n",
    "    try:\n",
    "        repo = github_client.get_repo(repo_name)\n",
    "        contents = repo.get_contents(path)\n",
    "        if isinstance(contents, list):\n",
    "            items = [f\"{'' if c.type=='dir' else ''} {c.name}\" for c in contents[:20]]\n",
    "            return f\"Contents of {repo_name}/{path or 'root'}:\\n\" + \"\\n\".join(items)\n",
    "        return str(contents)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "@tool\n",
    "@traceable\n",
    "def read_file_from_repo(repo_name: str, file_path: str, ref: str = \"main\") -> str:\n",
    "    \"\"\"Read a file from a repository.\"\"\"\n",
    "    try:\n",
    "        repo = github_client.get_repo(repo_name)\n",
    "        try:\n",
    "            file_content = repo.get_contents(file_path, ref=ref)\n",
    "        except:\n",
    "            file_content = repo.get_contents(file_path, ref=\"master\")\n",
    "        content = base64.b64decode(file_content.content).decode('utf-8')\n",
    "        return f\"# {file_path}\\n{'='*60}\\n{content}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "tools = [get_repository_info, list_repository_structure, read_file_from_repo]\n",
    "\n",
    "system_prompt = f\"\"\"GitHub Repository Analyzer Agent\n",
    "Date: {datetime.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "Analyze GitHub repositories using available tools.\n",
    "Be concise and use tools before answering.\n",
    "\"\"\"\n",
    "\n",
    "graph = create_react_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    state_schema=GitHubAgentState,\n",
    "    state_modifier=system_prompt\n",
    ")\n",
    "\n",
    "# This 'graph' variable will be detected by LangGraph Studio\n",
    "'''\n",
    "\n",
    "# Write to file\n",
    "with open('github_analyzer_studio.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(export_code)\n",
    "\n",
    "print(\" Exported agent to: github_analyzer_studio.py\")\n",
    "print(\"\\n To use in LangGraph Studio:\")\n",
    "print(\"   1. Open LangGraph Studio\")\n",
    "print(\"   2. Load 'github_analyzer_studio.py'\")\n",
    "print(\"   3. The 'graph' variable will be auto-detected\")\n",
    "print(\"   4. You can now visualize and test interactively!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Demo: Analyze Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " analyze_repository function ready (with full tracing)\n"
     ]
    }
   ],
   "source": [
    "@traceable(name=\"analyze_repository\")  # Trace the entire analysis\n",
    "def analyze_repository(repo_name: str, question: str):\n",
    "    \"\"\"Analyze a GitHub repository with a specific question.\"\"\"\n",
    "    \n",
    "    initial_state = get_initial_state()\n",
    "    initial_state[\"current_repo\"] = repo_name\n",
    "    initial_state[\"messages\"] = [\n",
    "        {\"role\": \"user\", \"content\": f\"Repository: {repo_name}\\n\\nQuestion: {question}\"}\n",
    "    ]\n",
    "    \n",
    "    print(f\" Analyzing: {repo_name}\")\n",
    "    print(f\" Question: {question}\")\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Show trace URL if enabled\n",
    "    if os.getenv(\"LANGCHAIN_TRACING_V2\") == \"true\":\n",
    "        print(\" LangSmith Trace: https://smith.langchain.com/\")\n",
    "        print(f\"   Project: {os.environ.get('LANGCHAIN_PROJECT', 'default')}\\n\")\n",
    "    \n",
    "    step_count = 0\n",
    "    for step in agent.stream(initial_state, stream_mode=\"updates\"):\n",
    "        step_count += 1\n",
    "        \n",
    "        if \"agent\" in step:\n",
    "            messages = step[\"agent\"].get(\"messages\", [])\n",
    "            for msg in messages:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(f\"\\n Agent (Step {step_count}):\")\n",
    "                    print(msg.content)\n",
    "                \n",
    "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                    for tc in msg.tool_calls:\n",
    "                        print(f\"\\n Calling tool: {tc['name']}\")\n",
    "                        print(f\"   Args: {tc['args']}\")\n",
    "        \n",
    "        if \"tools\" in step:\n",
    "            messages = step[\"tools\"].get(\"messages\", [])\n",
    "            for msg in messages:\n",
    "                if hasattr(msg, 'content'):\n",
    "                    content = msg.content[:300]\n",
    "                    print(f\"\\n Tool Result:\")\n",
    "                    print(content, \"...\" if len(msg.content) > 300 else \"\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\" Analysis complete! ({step_count} steps)\")\n",
    "\n",
    "print(\" analyze_repository function ready (with full tracing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Repository Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Analyzing: MAT496-Monsoon2025-SNU/capstone-template\n",
      " Question: What is this repository about? Give me a brief overview from its readme\n",
      "\n",
      "======================================================================\n",
      "\n",
      " LangSmith Trace: https://smith.langchain.com/\n",
      "   Project: GitHub-Analyzer-Simplified\n",
      "\n",
      "\n",
      " Calling tool: get_repository_info\n",
      "   Args: {'repo_name': 'MAT496-Monsoon2025-SNU/capstone-template'}\n",
      "\n",
      " Tool Result:\n",
      "# Repository: MAT496-Monsoon2025-SNU/capstone-template\n",
      "\n",
      "**Description:** No description\n",
      "**Stars:**  0\n",
      "**Forks:**  45\n",
      "**Language:** Not specified\n",
      "**Open Issues:**  0\n",
      "**Last Updated:** 2025-11-29 07:35:45+00:00\n",
      "**URL:** https://github.com/MAT496-Monsoon2025-SNU/capstone-template\n",
      " \n",
      "\n",
      " Calling tool: list_repository_structure\n",
      "   Args: {'repo_name': 'MAT496-Monsoon2025-SNU/capstone-template', 'max_depth': 1}\n",
      "\n",
      " Tool Result:\n",
      "Repository: MAT496-Monsoon2025-SNU/capstone-template\n",
      "Path: /root\n",
      "==================================================\n",
      "  .gitignore\n",
      "  README.md \n",
      "\n",
      " Calling tool: read_file_from_repo\n",
      "   Args: {'repo_name': 'MAT496-Monsoon2025-SNU/capstone-template', 'file_path': 'README.md'}\n",
      "\n",
      " Tool Result:\n",
      "# File: README.md\n",
      "Repository: MAT496-Monsoon2025-SNU/capstone-template\n",
      "Branch: main\n",
      "\n",
      "============================================================\n",
      "\n",
      "Template for creating and submitting MAT496 capstone project.\n",
      "\n",
      "# Overview of MAT496\n",
      "\n",
      "In this course, we have primarily learned Langgraph. This is helpful ...\n",
      "\n",
      " Agent (Step 7):\n",
      "The repository **MAT496-Monsoon2025-SNU/capstone-template** serves as a template for students to create and submit their capstone projects for the MAT496 course. Here’s a brief overview based on the README:\n",
      "\n",
      "### Overview\n",
      "The course focuses on using **Langgraph**, a tool for building applications that process unstructured text and extract information. Key topics covered include:\n",
      "- Prompting\n",
      "- Structured Output\n",
      "- Semantic Search\n",
      "- Retrieval Augmented Generation (RAG)\n",
      "- Tool calling LLMs & MCP\n",
      "- Langgraph concepts like State, Nodes, and Graph\n",
      "\n",
      "### Capstone Project Objectives\n",
      "The capstone project aims to:\n",
      "1. Revise major topics learned in the course.\n",
      "2. Encourage creativity by allowing students to tackle problems that were previously unsolvable with the course concepts. Examples include using LLMs for analyzing various types of news or building a legal assistant.\n",
      "\n",
      "### Project Structure\n",
      "The README provides a structured template for students to fill out, including sections for:\n",
      "- Project title and overview\n",
      "- Reason for project selection\n",
      "- Video summary link\n",
      "- A detailed plan with steps to complete the project\n",
      "- A conclusion reflecting on the project's achievements\n",
      "\n",
      "### Additional Instructions\n",
      "- The project is a solo assignment, and students must maintain a commit history that reflects their work over at least two days.\n",
      "- The deadline for submission is December 2nd, 2025.\n",
      "\n",
      "For more details, you can visit the repository [here](https://github.com/MAT496-Monsoon2025-SNU/capstone-template).\n",
      "\n",
      "======================================================================\n",
      " Analysis complete! (7 steps)\n"
     ]
    }
   ],
   "source": [
    "analyze_repository(\n",
    "    repo_name=\"MAT496-Monsoon2025-SNU/capstone-template\",\n",
    "    question=\"What is this repository about? Give me a brief overview from its readme\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Analyzing: MAT496-Monsoon2025-SNU/Kush-Sahni-2210110371-Langgraph-MAT496\n",
      " Question: What is the main directory structure and what are the main files?\n",
      "\n",
      "======================================================================\n",
      "\n",
      " LangSmith Trace: https://smith.langchain.com/\n",
      "   Project: GitHub-Analyzer-Simplified\n",
      "\n",
      "\n",
      " Calling tool: list_repository_structure\n",
      "   Args: {'repo_name': 'MAT496-Monsoon2025-SNU/Kush-Sahni-2210110371-Langgraph-MAT496', 'max_depth': 2}\n",
      "\n",
      " Tool Result:\n",
      "Repository: MAT496-Monsoon2025-SNU/Kush-Sahni-2210110371-Langgraph-MAT496\n",
      "Path: /root\n",
      "==================================================\n",
      "  langchain-academy-my-version/\n",
      "     module-0/\n",
      "        basics.ipynb\n",
      "     module-1/\n",
      "        studio/\n",
      "        agent-memory.ipynb\n",
      "        agent.ipynb\n",
      "        chain.ipy ...\n",
      "\n",
      " Agent (Step 3):\n",
      "The main directory structure of the repository **MAT496-Monsoon2025-SNU/Kush-Sahni-2210110371-Langgraph-MAT496** is as follows:\n",
      "\n",
      "```\n",
      "/root\n",
      "├── langchain-academy-my-version/\n",
      "│   ├── module-0/\n",
      "│   │   └── basics.ipynb\n",
      "│   ├── module-1/\n",
      "│   │   ├── agent-memory.ipynb\n",
      "│   │   ├── agent.ipynb\n",
      "│   │   ├── chain.ipynb\n",
      "│   │   ├── deployment.ipynb\n",
      "│   │   ├── router.ipynb\n",
      "│   │   └── simple-graph.ipynb\n",
      "│   ├── module-2/\n",
      "│   │   ├── chatbot-external-memory.ipynb\n",
      "│   │   ├── chatbot-summarization.ipynb\n",
      "│   │   ├── multiple-schemas.ipynb\n",
      "│   │   ├── state_db/\n",
      "│   │   ├── state-reducers.ipynb\n",
      "│   │   ├── state-schema.ipynb\n",
      "│   │   └── trim-filter-messages.ipynb\n",
      "│   ├── module-3/\n",
      "│   │   ├── breakpoints.ipynb\n",
      "│   │   ├── dynamic-breakpoints.ipynb\n",
      "│   │   ├── edit-state-human-feedback.ipynb\n",
      "│   │   ├── streaming-interruption.ipynb\n",
      "│   │   └── time-travel.ipynb\n",
      "│   ├── module-4/\n",
      "│   │   ├── map-reduce.ipynb\n",
      "│   │   ├── parallelization.ipynb\n",
      "│   │   ├── research-assistant.ipynb\n",
      "│   │   └── sub-graph.ipynb\n",
      "│   ├── module-5/\n",
      "│   │   ├── memory_agent.ipynb\n",
      "│   │   ├── memory_store.ipynb\n",
      "│   │   ├── memoryschema_collection.ipynb\n",
      "│   │   └── memoryschema_profile.ipynb\n",
      "│   └── module-6/\n",
      "│       ├── assistant.ipynb\n",
      "│       ├── connecting.ipynb\n",
      "│       ├── creating.ipynb\n",
      "│       └── double-texting.ipynb\n",
      "├── .gitignore\n",
      "├── requirements.txt\n",
      "├── README.md\n",
      "└── image-*.png (various image files)\n",
      "```\n",
      "\n",
      "### Main Files:\n",
      "- **README.md**: Provides an overview and documentation for the repository.\n",
      "- **requirements.txt**: Lists the dependencies required for the project.\n",
      "- **.gitignore**: Specifies files and directories that should be ignored by Git.\n",
      "- **Various image files**: These are likely used for documentation or illustrative purposes within the project.\n",
      "\n",
      "======================================================================\n",
      " Analysis complete! (3 steps)\n"
     ]
    }
   ],
   "source": [
    "analyze_repository(\n",
    "    repo_name=\"MAT496-Monsoon2025-SNU/Kush-Sahni-2210110371-Langgraph-MAT496\",\n",
    "    question=\"What is the main directory structure and what are the main files?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  Summary\n",
    "\n",
    "### What We Built\n",
    "\n",
    " **Full Agent with Tracing**\n",
    "- All functions decorated with `@traceable`\n",
    "- Complete visibility in LangSmith\n",
    "- Auto-export for LangGraph Studio\n",
    "\n",
    " **Observability Features**\n",
    "- See every LLM call\n",
    "- Track tool usage\n",
    "- Monitor costs\n",
    "- Debug issues\n",
    "\n",
    " **Files Created**\n",
    "- `github_analyzer_studio.py` - Ready for LangGraph Studio\n",
    "\n",
    "### View Your Traces\n",
    "\n",
    "1. Visit: https://smith.langchain.com/\n",
    "2. Navigate to your project: \"GitHub-Analyzer-Simplified\"\n",
    "3. See all runs with full details\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Add more tools\n",
    "- Test in LangGraph Studio\n",
    "- Share traces with team\n",
    "- Monitor production usage\n",
    "\n",
    "**Repository**: [Full Project](https://github.com/Kushcodingexe/Kush-Sahni-2210110371-GitHub-Repository-Analyzer-Agent-using-LangGraph-Git-MCP-MAT496)\n",
    "\n",
    "---\n",
    "*Built with LangGraph, traced with LangSmith* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
